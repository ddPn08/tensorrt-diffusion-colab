{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddPn08/tensorrt-diffusion-colab/blob/main/tensorrt_diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf9yH0YAW_Uc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Mount Google Drive\n",
        "mount_gdrive = True  # @param{type:\"boolean\"}\n",
        "\n",
        "if mount_gdrive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive', force_remount=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT27pk2sXIUO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "\n",
        "import os\n",
        "\n",
        "! curl -LO https://github.com/ddPn08/tensorrt-diffusion-colab/releases/download/tensorrt-8.5.2/libnvinfer_plugin.so.8\n",
        "! apt update && apt install software-properties-common -y && add-apt-repository --yes ppa:deadsnakes/ppa\n",
        "! apt update && apt install tensorrt tensorrt-dev tensorrt-libs git-lfs -y\n",
        "! git lfs install\n",
        "! git clone https://github.com/NVIDIA/TensorRT TensorRT\n",
        "\n",
        "TRT_OSSPATH = os.path.abspath(\"./TensorRT\")\n",
        "script_filepath = os.path.join(TRT_OSSPATH, \"demo\", \"Diffusion\", \"build.py\")\n",
        "\n",
        "! curl -o {script_filepath} -L https://raw.githubusercontent.com/ddPn08/tensorrt-diffusion-colab/main/scripts/build.py\n",
        "! pip install --upgrade pip\n",
        "! cd TensorRT/demo/Diffusion && pip install -r requirements.txt && pip install tensorrt accelerate numpy==1.21.6\n",
        "\n",
        "def make_args(d):\n",
        "    arguments = []\n",
        "    for k, v in d.items():\n",
        "        if type(v) == bool:\n",
        "            arguments.append(f\"--{k}\" if v else \"\")\n",
        "            continue\n",
        "        if type(v) == str and v:\n",
        "            arguments.extend([f\"--{k}\", f\"\\\"{v}\\\"\"])\n",
        "            continue\n",
        "        if type(v) == int or type(v) == float:\n",
        "            arguments.extend([f\"--{k}\", f\"{v}\"])\n",
        "            continue\n",
        "        if v:\n",
        "            arguments.extend([f\"--{k}\", f\"{v}\"])\n",
        "            continue\n",
        "    return \" \".join(arguments)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build tensorrt engine\n",
        "Convert the Diffusers model to TensorRT format.\n",
        "\n",
        "The converted model depends on the converted environment, so models with different GPUs may not be available."
      ],
      "metadata": {
        "id": "ZkxTmFzB-ghE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMsvoJuYstV0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Build\n",
        "import os\n",
        "\n",
        "def make_args(d):\n",
        "    arguments = []\n",
        "    for k, v in d.items():\n",
        "        k = k.replace(\"_\", \"-\")\n",
        "        if type(v) == bool:\n",
        "            arguments.append(f\"--{k}\" if v else \"\")\n",
        "        elif type(v) == str and v:\n",
        "            arguments.extend([f\"--{k}\", f\"{v}\"])\n",
        "        elif v:\n",
        "            arguments.extend([f\"--{k}\", f\"{v}\"])\n",
        "    return \" \".join(arguments)\n",
        "\n",
        "unet_pretrained_model_id = \"JosephusCheung/ACertainThing\"  # @param{type:\"string\"}\n",
        "vae_pretrained_model_id = \"JosephusCheung/ACertainThing\"  # @param{type:\"string\"}\n",
        "clip_pretrained_model_id = \"openai/clip-vit-large-patch14\"  # @param{type:\"string\"}\n",
        "\n",
        "os.environ[\"UNET_PRETRAINED_MODEL_ID\"] = unet_pretrained_model_id\n",
        "os.environ[\"VAE_PRETRAINED_MODEL_ID\"] = vae_pretrained_model_id\n",
        "os.environ[\"CLIP_PRETRAINED_MODEL_ID\"] = clip_pretrained_model_id\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "engine_dir = \"/content/engines/ACertainThing\"  # @param{type:\"string\"}\n",
        "onnx_dir = \"/content/onnx/ACertainThing\"  # @param{type:\"string\"}\n",
        "\n",
        "os.makedirs(engine_dir, exist_ok=True)\n",
        "os.makedirs(onnx_dir, exist_ok=True)\n",
        "\n",
        "# @markdown <br>\n",
        "\n",
        "hf_token = \"\"  # @param{type:\"string\"}\n",
        "denoising_prec = \"fp32\"  # @param [\"fp32\", \"fp16\"]\n",
        "scheduler = \"LMSD\"  # @param [\"LMSD\", \"DPM\"]\n",
        "height = 512  # @param{type:\"slider\", min:256, max:1024, step:64}\n",
        "width = 512  # @param{type:\"slider\", min:256, max:1024, step:64}\n",
        "\n",
        "onnx_opset = 16  # @param{type:\"integer\"}\n",
        "force_onnx_export = False  # @param{type:\"boolean\"}\n",
        "force_onnx_optimize = False  # @param{type:\"boolean\"}\n",
        "onnx_minimal_optimization = False  # @param{type:\"boolean\"}\n",
        "\n",
        "force_engine_build = False  # @param{type:\"boolean\"}\n",
        "build_static_batch = False  # @param{type:\"boolean\"}\n",
        "build_dynamic_shape = False  # @param{type:\"boolean\"}\n",
        "build_preview_features = False  # @param{type:\"boolean\"}\n",
        "\n",
        "args = make_args({\n",
        "    \"engine-dir\": engine_dir,\n",
        "    \"onnx-dir\": onnx_dir,\n",
        "    \"hf-token\": hf_token,\n",
        "    \"denoising-prec\": denoising_prec,\n",
        "    \"scheduler\": scheduler,\n",
        "    \"height\": height,\n",
        "    \"width\": width,\n",
        "    \"onnx-opset\": onnx_opset,\n",
        "    \"force-onnx-export\": force_onnx_export,\n",
        "    \"force-onnx-optimize\": force_onnx_optimize,\n",
        "    \"onnx-minimal-optimization\": onnx_minimal_optimization,\n",
        "    \"force-engine-build\": force_engine_build,\n",
        "    \"build-static-batch\": build_static_batch,\n",
        "    \"build-dynamic-shape\": build_dynamic_shape,\n",
        "    \"build-preview-features\": build_preview_features\n",
        "})\n",
        "\n",
        "! cd /content/TensorRT/demo/Diffusion && LD_PRELOAD=\"/content/libnvinfer_plugin.so.8\" python {script_filepath} {args}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload built engine to huggingface"
      ],
      "metadata": {
        "id": "olpViA5HcuLa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B80L5aABYthl",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Login to your Hugface account\n",
        "from huggingface_hub import login\n",
        "\n",
        "hf_token = \"\"  # @param{type:\"string\"}\n",
        "login(token=hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Upload built model to huggingface\n",
        "from huggingface_hub import create_repo, HfApi\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "user_name = \"\"  # @param{type:\"string\"}\n",
        "repository_name = \"\"  # @param{type:\"string\"}\n",
        "private = False  # @param{type:\"boolean\"}\n",
        "\n",
        "repo_id = f\"{user_name}/{repository_name}\"\n",
        "\n",
        "create_repo(repo_id, repo_type=repo_type, private=private)\n",
        "\n",
        "api.upload_folder(\n",
        "    folder_path=engine_dir,\n",
        "    path_in_repo=\"engine\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\"\n",
        ")\n",
        "api.upload_folder(\n",
        "    folder_path=onnx_dir,\n",
        "    path_in_repo=\"onnx\",\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"model\"\n",
        ")"
      ],
      "metadata": {
        "id": "u6qULsavbAGm",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference with the tensorrt engine\n",
        "Use pre-built engines for inference."
      ],
      "metadata": {
        "id": "Oc02UYYt_prN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "engines_dir = \"/content/engines\"\n",
        "engine_repository = \"ddPn08/ACertainThing-colab-tensorrt\"  # @param[\"https://huggingface.co/ddPn08/stable-diffusion-v1.4-colab-tensorrt\", \"ddPn08/ACertainThing-colab-tensorrt\"] {\"allow-input\": true}\n",
        "engine_repository_name = engine_repository.split(\"/\")[-1]\n",
        "\n",
        "url = f\"https://huggingface.co/{engine_repository}\"\n",
        "\n",
        "os.makedirs(engines_dir, exist_ok=True)\n",
        "\n",
        "! cd {engines_dir} && git clone {url}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OEp_KcG-_yeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "engine_dir = \"/content/engines/ACertainThing-colab-tensorrt/engine\"  # @param{type:\"string\"}\n",
        "output_dir = \"/content/outputs\"  # @param{type:\"string\"}\n",
        "hf_token = \"\"  # @param{type:\"string\"}\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# @markdown ---\n",
        "\n",
        "prompt = \"masterpiece, best quality, 1girl\"  # @param{type:\"string\"}\n",
        "negative_prompt = \"worst quality, low quality, deleted, lowres, bad anatomy, bad hands, text, error, missing fingers, extra digits, fewer digits, cropped, jpeg artifacts, signature, watermark, username, blurry\"  # @param{type:\"string\"}\n",
        "repeat_prompt = 1  # @param{type:\"integer\"}\n",
        "height = 512  # @param{type:\"slider\", min:256, max:1024, step:64}\n",
        "width = 512  # @param{type:\"slider\", min:256, max:1024, step:64}\n",
        "denoising_steps = 150  # @param{type:\"integer\"}\n",
        "denoising_prec = \"fp32\"  # @param [\"fp32\", \"fp16\"]\n",
        "scheduler = \"LMSD\"  # @param [\"LMSD\", \"DPM\"]\n",
        "seed = \"1\"  # @param{type:\"string\"}\n",
        "\n",
        "num_warmup_runs = 0  # @param{type:\"integer\"}\n",
        "\n",
        "args = make_args({\n",
        "    \"engine-dir\": engine_dir,\n",
        "    \"output-dir\": output_dir,\n",
        "    \"negative-prompt\": negative_prompt,\n",
        "    \"repeat-prompt\": repeat_prompt,\n",
        "    \"height\": height,\n",
        "    \"width\": height,\n",
        "    \"denoising-steps\": denoising_steps,\n",
        "    \"denoising-prec\": denoising_prec,\n",
        "    \"scheduler\": scheduler,\n",
        "    \"seed\": seed,\n",
        "    \"num-warmup-runs\": num_warmup_runs\n",
        "})\n",
        "\n",
        "! cd /content/TensorRT/demo/Diffusion \\\n",
        "    && LD_PRELOAD=\"/content/libnvinfer_plugin.so.8\" accelerate launch demo-diffusion.py \"{prompt}\" {args}"
      ],
      "metadata": {
        "id": "RHR74sk6bszi",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UwdMyjL6UcjI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1j_HsAlauH9rVC3mZd2C5EYir_VAaYlB3",
      "authorship_tag": "ABX9TyPdNd14DAxduPkm77BsHcPG",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}